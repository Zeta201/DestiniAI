{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jtveQkGRmWA_bMTbr-RGBNM5mJO0muBv","timestamp":1743616139407}],"authorship_tag":"ABX9TyOZyUbSXkfteQ9AkNezGhLK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQOWhSnI_Mnn","executionInfo":{"status":"ok","timestamp":1743604693879,"user_tz":-330,"elapsed":8881,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"86e00d2e-8c2f-4799-eed2-1e555e8541db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 2.0.2\n","Uninstalling numpy-2.0.2:\n","  Successfully uninstalled numpy-2.0.2\n","Collecting numpy<2\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","Successfully installed numpy-1.26.4\n"]}],"source":["!pip uninstall numpy -y\n","!pip install \"numpy<2\""]},{"cell_type":"code","source":["!pip uninstall torch torchvision torchaudio -y\n","!pip install torch==2.5.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tKlkhNc5KYk","executionInfo":{"status":"ok","timestamp":1743616431601,"user_tz":-330,"elapsed":192783,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"47e29d8a-7eb4-43c2-ef2b-f396cf176b40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.6.0+cu124\n","Uninstalling torch-2.6.0+cu124:\n","  Successfully uninstalled torch-2.6.0+cu124\n","Found existing installation: torchvision 0.21.0+cu124\n","Uninstalling torchvision-0.21.0+cu124:\n","  Successfully uninstalled torchvision-0.21.0+cu124\n","Found existing installation: torchaudio 2.6.0+cu124\n","Uninstalling torchaudio-2.6.0+cu124:\n","  Successfully uninstalled torchaudio-2.6.0+cu124\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch==2.5.0\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.0%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0)\n","  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.0) (12.5.82)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.0%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.0+cu121 torchaudio-2.5.0+cu121 torchvision-0.20.0+cu121 triton-3.1.0\n"]}]},{"cell_type":"code","source":["!pip install surprise faker\n","!pip install torch_geometric\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.5.0+cu121.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqx6RxeG_Otn","executionInfo":{"status":"ok","timestamp":1743616529591,"user_tz":-330,"elapsed":85556,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"c5ccaa4c-093a-42da-fe63-f78f0bfe595c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting surprise\n","  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n","Collecting faker\n","  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n","Collecting scikit-surprise (from surprise)\n","  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.4.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.14.1)\n","Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n","Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505210 sha256=eb8375fb7cd270dbf45e0d7ae8a93a86ce50969563ecb3f2e7df9e7cc55eec90\n","  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n","Successfully built scikit-surprise\n","Installing collected packages: faker, scikit-surprise, surprise\n","Successfully installed faker-37.1.0 scikit-surprise-1.1.4 surprise-0.1\n","Collecting torch_geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n","Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu121.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n","Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18+pt25cu121\n"]}]},{"cell_type":"code","source":["import torch\n","print(\"Torch version:\", torch.__version__)\n","print(\"CUDA version:\", torch.version.cuda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2WdS4N03W_u","executionInfo":{"status":"ok","timestamp":1743607055025,"user_tz":-330,"elapsed":3183,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"9fbafc22-2e5d-42c6-db41-8a226837782b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 2.5.0+cu121\n","CUDA version: 12.1\n"]}]},{"cell_type":"code","source":["import random\n","import pandas as pd\n","from faker import Faker\n","\n","# Initialize Faker\n","fake = Faker()\n","\n","# Generate random users with location coordinates\n","def generate_users(n=1000):\n","    start_date = pd.to_datetime(\"2023-01-01\")  # Earliest possible signup date\n","    end_date = pd.to_datetime(\"2024-04-01\")  # Latest possible signup date\n","    data = {\n","        'user_id': list(range(1, n + 1)),\n","        'name': [fake.name() for _ in range(n)],\n","        'age': [random.randint(18, 50) for _ in range(n)],\n","        'gender': [random.choice(['M', 'F', 'Non-binary']) for _ in range(n)],\n","        'location': [fake.city() for _ in range(n)],\n","        'latitude': [round(random.uniform(-90, 90), 6) for _ in range(n)],  # Random latitude\n","        'longitude': [round(random.uniform(-180, 180), 6) for _ in range(n)],  # Random longitude\n","        'interests': [', '.join(random.sample(\n","            ['music', 'travel', 'sports', 'technology', 'art', 'reading', 'gaming', 'photography', 'cooking', 'fitness'], 3)) for _ in range(n)],\n","        'about_me': [fake.sentence(nb_words=10) for _ in range(n)],\n","        'relationship_goal': [random.choice(['Casual Dating', 'Long-term', 'Friends', 'Networking']) for _ in range(n)],\n","        'personality': [random.choice(['Introvert', 'Extrovert', 'Ambivert']) for _ in range(n)],\n","        'MBTI': [random.choice(['INFJ', 'ENTP', 'ISTJ', 'ENFP', 'ISFJ', 'ESTP', 'INTP', 'ESFJ']) for _ in range(n)],\n","        'likes': [random.sample(range(1, n + 1), random.randint(5, 15)) for _ in range(n)],\n","        'swipes': [random.randint(10, 500) for _ in range(n)],\n","        'messages_sent': [random.randint(0, 100) for _ in range(n)],\n","        'response_rate': [round(random.uniform(0.2, 1.0), 2) for _ in range(n)],\n","        'signup_date': [fake.date_between(start_date=start_date, end_date=end_date) for _ in range(n)]\n","    }\n","    return pd.DataFrame(data)\n"],"metadata":{"id":"5_MuC13C_nd1","executionInfo":{"status":"ok","timestamp":1743623278841,"user_tz":-330,"elapsed":15,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["df_users = generate_users(1000)"],"metadata":{"id":"Iaa8WHF5Ckqj","executionInfo":{"status":"ok","timestamp":1743623345842,"user_tz":-330,"elapsed":241,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["# Content Based Filtering (CBF)"],"metadata":{"id":"-o3sCdDLBG7B"}},{"cell_type":"markdown","source":["# GNN for Content Based Matching"],"metadata":{"id":"66zS7GRRGxhI"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch_geometric\n","from torch_geometric.nn import SAGEConv\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer\n","from sklearn.preprocessing import MinMaxScaler\n","from torch_geometric.data import Data\n","import random\n","from scipy.spatial.distance import cdist\n","\n","# Set up GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Function to calculate haversine distance (in kilometers)\n","def haversine(lat1, lon1, lat2, lon2):\n","    R = 6371  # Radius of Earth in km\n","    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n","    delta_phi = np.radians(lat2 - lat1)\n","    delta_lambda = np.radians(lon2 - lon1)\n","\n","    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2)**2\n","    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n","    return R * c\n","\n","# Optimized build_graph function with vectorized Haversine distance calculation\n","def build_graph(df_users, content_matrix, normalized_numerical, top_k=10):\n","    num_users = len(df_users)\n","\n","    # Compute content and numerical similarities\n","    content_similarity = cosine_similarity(content_matrix)\n","    num_similarity = 1 / (1 + cdist(normalized_numerical, normalized_numerical, metric='euclidean'))\n","\n","    # Compute location similarity using vectorized Haversine formula\n","    latitudes = df_users['latitude'].values\n","    longitudes = df_users['longitude'].values\n","\n","    # Create meshgrid for latitudes and longitudes\n","    latitudes_grid, longitudes_grid = np.meshgrid(latitudes, latitudes)\n","    longitudes_grid, latitudes_grid = np.meshgrid(longitudes, longitudes)\n","\n","    # Calculate pairwise distances using Haversine\n","    distances = haversine(latitudes_grid, longitudes_grid, latitudes_grid.T, longitudes_grid.T)\n","\n","    # Convert distances to similarity (using exponential decay function)\n","    location_similarity = np.exp(-distances / 100)  # Decay with distance\n","\n","    # Combine all similarity matrices (content, numerical, and location)\n","    similarity_matrix = 0.33 * content_similarity + 0.33 * num_similarity + 0.33 * location_similarity\n","\n","    # Keep only top-k edges per node\n","    edge_list = []\n","    for i in range(num_users):\n","        top_k_neighbors = np.argsort(-similarity_matrix[i])[:top_k]  # Get top-k most similar users\n","        for j in top_k_neighbors:\n","            if i != j:  # Avoid self-loops\n","                edge_list.append((i, j))\n","\n","    # Convert edges to PyG format\n","    edge_index = torch.tensor(np.array(edge_list).T, dtype=torch.long).to(device)\n","\n","    # Node features (content and numerical)\n","    node_features = np.hstack([content_matrix, normalized_numerical])\n","    x = torch.tensor(node_features, dtype=torch.float).to(device)\n","\n","    return Data(x=x, edge_index=edge_index)\n","\n","# Prepare user feature matrices\n","def build_feature_matrices(df_users):\n","    df_users['content'] = df_users['interests'] + ' ' + df_users['about_me'] + ' ' + df_users['personality'] + ' ' + df_users['MBTI'] + ' ' + df_users['relationship_goal']\n","\n","    # Truncate or pad content\n","    content_matrix = np.array(sentence_model.encode(df_users['content'], convert_to_numpy=True))\n","\n","    scaler = MinMaxScaler()\n","    numerical_features = df_users[['age', 'response_rate', 'messages_sent']].astype(float)\n","    normalized_numerical = scaler.fit_transform(numerical_features)\n","\n","    return content_matrix, normalized_numerical, scaler\n","\n","# Modify pair creation for contrastive learning\n","# Modify pair creation for contrastive learning\n","# Now considers multiple factors: relationship goal, interests, MBTI type, age difference, response rate similarity, and location similarity\n","def create_contrastive_pairs(df_users, batch_size=512):\n","    indices = np.random.choice(len(df_users), (batch_size, 2), replace=True)\n","    pairs = torch.tensor(indices, dtype=torch.long).to(device)\n","\n","    # Compute similarity labels based on multiple criteria\n","    same_relationship = df_users.iloc[pairs[:, 0]]['relationship_goal'].values == df_users.iloc[pairs[:, 1]]['relationship_goal'].values\n","    same_mbti = df_users.iloc[pairs[:, 0]]['MBTI'].values == df_users.iloc[pairs[:, 1]]['MBTI'].values\n","\n","    # Compute Jaccard similarity for interests\n","    interests1 = df_users.iloc[pairs[:, 0]]['interests'].apply(lambda x: set(x.split(', ')))\n","    interests2 = df_users.iloc[pairs[:, 1]]['interests'].apply(lambda x: set(x.split(', ')))\n","    jaccard_sim = [len(i1 & i2) / len(i1 | i2) if len(i1 | i2) > 0 else 0 for i1, i2 in zip(interests1, interests2)]\n","\n","    # Normalize numerical features: age difference and response rate similarity\n","    age_diff = np.abs(df_users.iloc[pairs[:, 0]]['age'].values - df_users.iloc[pairs[:, 1]]['age'].values)\n","    max_age = df_users['age'].max()\n","    age_similarity = 1 - (age_diff / max_age)  # Normalize to [0,1]\n","\n","    response_rate_diff = np.abs(df_users.iloc[pairs[:, 0]]['response_rate'].values - df_users.iloc[pairs[:, 1]]['response_rate'].values)\n","    response_similarity = 1 - response_rate_diff  # Since response rate is already in [0,1]\n","\n","    # Compute location similarity using haversine distance\n","    lat1, lon1 = df_users.iloc[pairs[:, 0]]['latitude'].values, df_users.iloc[pairs[:, 0]]['longitude'].values\n","    lat2, lon2 = df_users.iloc[pairs[:, 1]]['latitude'].values, df_users.iloc[pairs[:, 1]]['longitude'].values\n","    distances = haversine(lat1, lon1, lat2, lon2)\n","    location_similarity = np.exp(-distances / 100)  # Exponential decay based on distance\n","\n","    # Weighted combination of criteria (weights can be adjusted)\n","    labels = (0.35 * same_relationship.astype(float) +\n","              0.2 * same_mbti.astype(float) +\n","              0.15 * np.array(jaccard_sim) +\n","              0.1 * age_similarity +\n","              0.1 * response_similarity +\n","              0.1 * location_similarity)\n","    labels = torch.tensor(labels, dtype=torch.float).to(device)\n","\n","    return pairs.t(), labels\n","\n","# GNN Training Function\n","def train_gnn(data, df_users):\n","    model = GraphSAGE(in_channels=data.x.shape[1], out_channels=16).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    criterion = ContrastiveLoss(margin=0.5).to(device)\n","\n","    for epoch in range(100):\n","        model.train()\n","        optimizer.zero_grad()\n","        out = model(data)\n","\n","        # Move data to GPU\n","        pair_indices, labels = create_contrastive_pairs(df_users, batch_size=512)\n","\n","        # Apply contrastive loss to output pairs\n","        output1 = out[pair_indices[0]]\n","        output2 = out[pair_indices[1]]\n","        loss = criterion(output1, output2, labels)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n","\n","    return model\n","\n","# GraphSAGE Model Definition\n","class GraphSAGE(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GraphSAGE, self).__init__()\n","        self.conv1 = SAGEConv(in_channels, 64)\n","        self.conv2 = SAGEConv(64, out_channels)\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","# Contrastive Loss Class Definition\n","class ContrastiveLoss(torch.nn.Module):\n","    def __init__(self, margin=0.5):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","\n","    def forward(self, output1, output2, label):\n","        dist = F.pairwise_distance(output1, output2, p=2)\n","        loss = 0.5 * (label * torch.pow(dist, 2) + (1 - label) * torch.pow(torch.clamp(self.margin - dist, min=0.0), 2))\n","        return loss.mean()\n","\n","# Recommendation Logic\n","def recommend_users_with_gnn(user_id, df_users, data, model, top_n=5):\n","    user_idx = df_users[df_users['user_id'] == user_id].index[0]\n","\n","    # Set model to evaluation mode\n","    model.eval()\n","    with torch.no_grad():\n","        user_embeddings = model(data).cpu().numpy()\n","\n","    # Get the user's embedding\n","    user_embedding = user_embeddings[user_idx]\n","\n","    # Compute cosine similarity\n","    similarities = cosine_similarity([user_embedding], user_embeddings).flatten()\n","\n","    # Get top N similar users (excluding the user themselves)\n","    similar_users_idx = similarities.argsort()[-(top_n+1):-1][::-1]\n","    recommended_users = df_users.iloc[similar_users_idx].copy()\n","\n","    # Add similarity scores to recommendations\n","    recommended_users[\"similarity_score\"] = similarities[similar_users_idx]\n","\n","    # # Display results\n","    # print(f\"\\nRecommendations for User {user_id}:\")\n","    # print(recommended_users[['user_id', 'name', 'interests', 'personality',\n","    #                          'MBTI', 'relationship_goal', 'location', 'similarity_score']])\n","\n","    return recommended_users\n","\n","# Final Execution\n","\n","# Prepare user data\n","sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Prepare feature matrices\n","content_matrix, normalized_numerical, scaler = build_feature_matrices(df_users)\n","data = build_graph(df_users, content_matrix, normalized_numerical)\n","\n","# Train GNN model on GPU\n","model = train_gnn(data, df_users)\n","\n","# Get recommendations for a user\n","user_id = 1\n","print(f\"Recommendations for User {user_id}:\")\n","recommend_users_with_gnn(user_id, df_users, data, model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"44ydMRs0JB9I","executionInfo":{"status":"ok","timestamp":1743623365861,"user_tz":-330,"elapsed":18673,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"93ab5186-7d50-4da6-ecf2-bfdf90d8b03b"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","Epoch 0, Loss: 0.06123325228691101\n","Epoch 10, Loss: 0.02930455096065998\n","Epoch 20, Loss: 0.027853047475218773\n","Epoch 30, Loss: 0.0276931319385767\n","Epoch 40, Loss: 0.027154704555869102\n","Epoch 50, Loss: 0.0264628566801548\n","Epoch 60, Loss: 0.025150950998067856\n","Epoch 70, Loss: 0.026019399985671043\n","Epoch 80, Loss: 0.02480792999267578\n","Epoch 90, Loss: 0.02475106343626976\n","Recommendations for User 1:\n"]},{"output_type":"execute_result","data":{"text/plain":["     user_id                name  age      gender        location   latitude  \\\n","990      991       Angela Torres   19           F        Alanfort  49.905009   \n","266      267        Miguel Wiley   38  Non-binary  Mclaughlintown  71.048943   \n","65        66  Katherine Williams   25  Non-binary     Comptonfort -36.728096   \n","360      361        Crystal Reid   25  Non-binary    Karenborough -45.891344   \n","59        60      Alexander Khan   27           F     Reedborough  22.944507   \n","\n","      longitude                     interests  \\\n","990  -82.650041        music, travel, fitness   \n","266  101.136208  gaming, photography, reading   \n","65   162.540959       sports, gaming, fitness   \n","360 -119.955338          reading, art, sports   \n","59   -33.505786    photography, music, gaming   \n","\n","                                              about_me relationship_goal  \\\n","990  Lay page ten quickly visit news eye religious ...           Friends   \n","266  Increase it process lead friend capital marria...           Friends   \n","65   President mention marriage five source quite per.           Friends   \n","360  Money billion check sport bank skill away area...           Friends   \n","59          Address three create realize water become.           Friends   \n","\n","    personality  MBTI                                              likes  \\\n","990   Introvert  ISTJ                          [377, 681, 399, 254, 985]   \n","266   Introvert  ENFP  [654, 32, 409, 935, 724, 447, 459, 31, 531, 94...   \n","65    Introvert  ISFJ  [675, 311, 123, 150, 11, 656, 134, 65, 30, 609...   \n","360   Introvert  INTP  [261, 435, 814, 704, 544, 714, 555, 440, 633, ...   \n","59    Extrovert  INTP                           [722, 63, 700, 729, 974]   \n","\n","     swipes  messages_sent  response_rate signup_date  \\\n","990     230             77           0.81  2024-02-12   \n","266     409             67           0.90  2023-08-30   \n","65      222             97           0.69  2023-08-22   \n","360     301             82           0.80  2023-10-31   \n","59      308             94           0.98  2024-03-27   \n","\n","                                               content  similarity_score  \n","990  music, travel, fitness Lay page ten quickly vi...          0.985961  \n","266  gaming, photography, reading Increase it proce...          0.974876  \n","65   sports, gaming, fitness President mention marr...          0.971631  \n","360  reading, art, sports Money billion check sport...          0.971540  \n","59   photography, music, gaming Address three creat...          0.968983  "],"text/html":["\n","  <div id=\"df-fa523e96-da58-4942-ab5e-6834412d5d45\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>name</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>location</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>interests</th>\n","      <th>about_me</th>\n","      <th>relationship_goal</th>\n","      <th>personality</th>\n","      <th>MBTI</th>\n","      <th>likes</th>\n","      <th>swipes</th>\n","      <th>messages_sent</th>\n","      <th>response_rate</th>\n","      <th>signup_date</th>\n","      <th>content</th>\n","      <th>similarity_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>990</th>\n","      <td>991</td>\n","      <td>Angela Torres</td>\n","      <td>19</td>\n","      <td>F</td>\n","      <td>Alanfort</td>\n","      <td>49.905009</td>\n","      <td>-82.650041</td>\n","      <td>music, travel, fitness</td>\n","      <td>Lay page ten quickly visit news eye religious ...</td>\n","      <td>Friends</td>\n","      <td>Introvert</td>\n","      <td>ISTJ</td>\n","      <td>[377, 681, 399, 254, 985]</td>\n","      <td>230</td>\n","      <td>77</td>\n","      <td>0.81</td>\n","      <td>2024-02-12</td>\n","      <td>music, travel, fitness Lay page ten quickly vi...</td>\n","      <td>0.985961</td>\n","    </tr>\n","    <tr>\n","      <th>266</th>\n","      <td>267</td>\n","      <td>Miguel Wiley</td>\n","      <td>38</td>\n","      <td>Non-binary</td>\n","      <td>Mclaughlintown</td>\n","      <td>71.048943</td>\n","      <td>101.136208</td>\n","      <td>gaming, photography, reading</td>\n","      <td>Increase it process lead friend capital marria...</td>\n","      <td>Friends</td>\n","      <td>Introvert</td>\n","      <td>ENFP</td>\n","      <td>[654, 32, 409, 935, 724, 447, 459, 31, 531, 94...</td>\n","      <td>409</td>\n","      <td>67</td>\n","      <td>0.90</td>\n","      <td>2023-08-30</td>\n","      <td>gaming, photography, reading Increase it proce...</td>\n","      <td>0.974876</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>66</td>\n","      <td>Katherine Williams</td>\n","      <td>25</td>\n","      <td>Non-binary</td>\n","      <td>Comptonfort</td>\n","      <td>-36.728096</td>\n","      <td>162.540959</td>\n","      <td>sports, gaming, fitness</td>\n","      <td>President mention marriage five source quite per.</td>\n","      <td>Friends</td>\n","      <td>Introvert</td>\n","      <td>ISFJ</td>\n","      <td>[675, 311, 123, 150, 11, 656, 134, 65, 30, 609...</td>\n","      <td>222</td>\n","      <td>97</td>\n","      <td>0.69</td>\n","      <td>2023-08-22</td>\n","      <td>sports, gaming, fitness President mention marr...</td>\n","      <td>0.971631</td>\n","    </tr>\n","    <tr>\n","      <th>360</th>\n","      <td>361</td>\n","      <td>Crystal Reid</td>\n","      <td>25</td>\n","      <td>Non-binary</td>\n","      <td>Karenborough</td>\n","      <td>-45.891344</td>\n","      <td>-119.955338</td>\n","      <td>reading, art, sports</td>\n","      <td>Money billion check sport bank skill away area...</td>\n","      <td>Friends</td>\n","      <td>Introvert</td>\n","      <td>INTP</td>\n","      <td>[261, 435, 814, 704, 544, 714, 555, 440, 633, ...</td>\n","      <td>301</td>\n","      <td>82</td>\n","      <td>0.80</td>\n","      <td>2023-10-31</td>\n","      <td>reading, art, sports Money billion check sport...</td>\n","      <td>0.971540</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>60</td>\n","      <td>Alexander Khan</td>\n","      <td>27</td>\n","      <td>F</td>\n","      <td>Reedborough</td>\n","      <td>22.944507</td>\n","      <td>-33.505786</td>\n","      <td>photography, music, gaming</td>\n","      <td>Address three create realize water become.</td>\n","      <td>Friends</td>\n","      <td>Extrovert</td>\n","      <td>INTP</td>\n","      <td>[722, 63, 700, 729, 974]</td>\n","      <td>308</td>\n","      <td>94</td>\n","      <td>0.98</td>\n","      <td>2024-03-27</td>\n","      <td>photography, music, gaming Address three creat...</td>\n","      <td>0.968983</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa523e96-da58-4942-ab5e-6834412d5d45')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fa523e96-da58-4942-ab5e-6834412d5d45 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fa523e96-da58-4942-ab5e-6834412d5d45');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-99216cbc-3f1e-4172-8fc9-ea319f31010d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99216cbc-3f1e-4172-8fc9-ea319f31010d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-99216cbc-3f1e-4172-8fc9-ea319f31010d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["df_users[df_users['user_id']==1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"b7s9ykYkBhS9","executionInfo":{"status":"ok","timestamp":1743623369045,"user_tz":-330,"elapsed":70,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"53d7f07b-f38d-4a22-a21b-559dcb927b18"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   user_id         name  age gender   location   latitude   longitude  \\\n","0        1  Jill Willis   18      F  Ericshire  28.287027  102.025163   \n","\n","                    interests  \\\n","0  music, photography, gaming   \n","\n","                                            about_me relationship_goal  \\\n","0  Itself condition with center thought then step...           Friends   \n","\n","  personality  MBTI                                              likes  \\\n","0   Introvert  INFJ  [720, 967, 530, 155, 776, 463, 787, 715, 802, ...   \n","\n","   swipes  messages_sent  response_rate signup_date  \\\n","0      69             98           0.91  2023-07-08   \n","\n","                                             content  \n","0  music, photography, gaming Itself condition wi...  "],"text/html":["\n","  <div id=\"df-2ceaef4b-a166-4ddd-bcdb-16aa62c53266\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>name</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>location</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>interests</th>\n","      <th>about_me</th>\n","      <th>relationship_goal</th>\n","      <th>personality</th>\n","      <th>MBTI</th>\n","      <th>likes</th>\n","      <th>swipes</th>\n","      <th>messages_sent</th>\n","      <th>response_rate</th>\n","      <th>signup_date</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Jill Willis</td>\n","      <td>18</td>\n","      <td>F</td>\n","      <td>Ericshire</td>\n","      <td>28.287027</td>\n","      <td>102.025163</td>\n","      <td>music, photography, gaming</td>\n","      <td>Itself condition with center thought then step...</td>\n","      <td>Friends</td>\n","      <td>Introvert</td>\n","      <td>INFJ</td>\n","      <td>[720, 967, 530, 155, 776, 463, 787, 715, 802, ...</td>\n","      <td>69</td>\n","      <td>98</td>\n","      <td>0.91</td>\n","      <td>2023-07-08</td>\n","      <td>music, photography, gaming Itself condition wi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ceaef4b-a166-4ddd-bcdb-16aa62c53266')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2ceaef4b-a166-4ddd-bcdb-16aa62c53266 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2ceaef4b-a166-4ddd-bcdb-16aa62c53266');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df_users[df_users['user_id']==1]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Jill Willis\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 18,\n        \"max\": 18,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ericshire\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 28.287027,\n        \"max\": 28.287027,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          28.287027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 102.025163,\n        \"max\": 102.025163,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          102.025163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"interests\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"music, photography, gaming\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"about_me\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Itself condition with center thought then step meeting full hear tough fish.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship_goal\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Friends\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"personality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Introvert\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MBTI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"INFJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"likes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swipes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 69,\n        \"max\": 69,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"messages_sent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 98,\n        \"max\": 98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.91,\n        \"max\": 0.91,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"signup_date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-07-08\",\n        \"max\": \"2023-07-08\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2023-07-08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"music, photography, gaming Itself condition with center thought then step meeting full hear tough fish. Introvert INFJ Friends\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["# Colaborative Filtering"],"metadata":{"id":"TNwI8-iLBK7c"}},{"cell_type":"code","source":["import pandas as pd\n","import random\n","from surprise import Dataset, Reader, SVD\n","from surprise.model_selection import train_test_split\n","from surprise import accuracy\n","from surprise.model_selection import cross_validate\n","\n","def generate_interactions(n_users=1000, n_items=100):\n","    interactions = []\n","    for user in range(1, n_users + 1):\n","        for _ in range(random.randint(5, 15)):  # Each user interacts with 5-15 profiles\n","            item = random.randint(1, n_items)  # Random profile ID\n","            rating = random.choice([1, 2, 3, 4, 5])  # Rating simulating a like or preference strength\n","            interactions.append((user, item, rating))\n","    return pd.DataFrame(interactions, columns=['user_id', 'profile_id', 'rating'])\n","\n","def build_collaborative_filtering_model(df):\n","    \"\"\"Trains an SVD model on user-profile interactions.\"\"\"\n","    reader = Reader(rating_scale=(1, 5))\n","    data = Dataset.load_from_df(df[['user_id', 'profile_id', 'rating']], reader)\n","    trainset, testset = train_test_split(data, test_size=0.2)\n","    model = SVD()\n","    model.fit(trainset)\n","    predictions = model.test(testset)\n","    print(f\"Model RMSE: {accuracy.rmse(predictions)}\")\n","    return model, data.build_full_trainset()\n","\n","def recommend_profiles(user_id, model, trainset, top_n=5):\n","    \"\"\"Recommends top N profiles for a given user based on learned preferences.\"\"\"\n","    known_items = set(trainset.ur[trainset.to_inner_uid(user_id)])\n","    all_items = set(range(trainset.n_items))\n","    unknown_items = all_items - known_items\n","    predictions = [(iid, model.predict(user_id, iid).est) for iid in unknown_items]\n","    top_profiles = sorted(predictions, key=lambda x: x[1], reverse=True)[:top_n]\n","    return [profile_id for profile_id, _ in top_profiles]\n","\n","# Generate user-profile interactions\n","df_interactions = generate_interactions()\n","\n","# Train the collaborative filtering model\n","model, trainset = build_collaborative_filtering_model(df_interactions)\n","\n","# Recommend profiles for a random user\n","# user_id = random.choice(df_interactions['user_id'].tolist())\n","user_id = 1\n","print(f\"Recommended profiles for User {user_id}: {recommend_profiles(user_id, model, trainset)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDFbaRk-Ax8q","executionInfo":{"status":"ok","timestamp":1743581032449,"user_tz":-330,"elapsed":111,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"949e322b-c232-475b-8a0d-989e38b37eee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 1.4804\n","Model RMSE: 1.4804406786415283\n","Recommended profiles for User 1: [2, 23, 94, 80, 46]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import random\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from surprise import Dataset, Reader, SVD\n","from surprise.model_selection import train_test_split\n","from surprise import accuracy\n","\n","def generate_users(n=100):\n","    data = {\n","        'user_id': list(range(1, n + 1)),\n","        'name': [fake.name() for _ in range(n)],\n","        'age': [random.randint(18, 50) for _ in range(n)],\n","        'gender': [random.choice(['M', 'F', 'Non-binary']) for _ in range(n)],\n","        'location': [fake.city() for _ in range(n)],\n","        'interests': [', '.join(random.sample(\n","            ['music', 'travel', 'sports', 'technology', 'art', 'reading', 'gaming', 'photography', 'cooking', 'fitness'], 3)) for _ in range(n)],\n","        'about_me': [fake.sentence(nb_words=10) for _ in range(n)],\n","        'relationship_goal': [random.choice(['Casual Dating', 'Long-term', 'Friends', 'Networking']) for _ in range(n)],\n","        'personality': [random.choice(['Introvert', 'Extrovert', 'Ambivert']) for _ in range(n)],\n","        'MBTI': [random.choice(['INFJ', 'ENTP', 'ISTJ', 'ENFP', 'ISFJ', 'ESTP', 'INTP', 'ESFJ']) for _ in range(n)],\n","        'likes': [random.sample(range(1, n + 1), random.randint(5, 15)) for _ in range(n)],\n","        'swipes': [random.randint(10, 500) for _ in range(n)],\n","        'messages_sent': [random.randint(0, 100) for _ in range(n)],\n","        'response_rate': [round(random.uniform(0.2, 1.0), 2) for _ in range(n)],\n","    }\n","    return pd.DataFrame(data)\n","\n","\n","def generate_interactions(n_users=100, n_items=50):\n","    interactions = []\n","    for user in range(1, n_users + 1):\n","        for _ in range(random.randint(5, 15)):\n","            item = random.randint(1, n_items)\n","            rating = random.choice([1, 2, 3, 4, 5])\n","            interactions.append((user, item, rating))\n","    return pd.DataFrame(interactions, columns=['user_id', 'profile_id', 'rating'])\n","\n","def build_content_matrix(df):\n","    df['content'] = df['interests'] + ' ' + df['personality'] + ' ' + df['about_me'] + ' ' + df['MBTI'] + ' ' + df['location'] + ' ' + df['relationship_goal']\n","    vectorizer = TfidfVectorizer()\n","    content_matrix = vectorizer.fit_transform(df['content'])\n","    return content_matrix, vectorizer\n","\n","def build_cf_model(df):\n","    reader = Reader(rating_scale=(1, 5))\n","    data = Dataset.load_from_df(df[['user_id', 'profile_id', 'rating']], reader)\n","    trainset, _ = train_test_split(data, test_size=0.2)\n","    model = SVD()\n","    model.fit(trainset)\n","    return model, data.build_full_trainset()\n","\n","def update_feedback(user_id, profile_id, rating, df_interactions, cf_model):\n","    \"\"\"Updates user feedback and retrains CF model.\"\"\"\n","    new_entry = pd.DataFrame([[user_id, profile_id, rating]], columns=['user_id', 'profile_id', 'rating'])\n","    df_interactions = pd.concat([df_interactions, new_entry], ignore_index=True)\n","    cf_model, trainset = build_cf_model(df_interactions)\n","    return df_interactions, cf_model, trainset\n","\n","def hybrid_recommend(user_id, df_users, df_interactions, content_matrix, cf_model, trainset, top_n=5):\n","    \"\"\"Combines content-based and collaborative filtering recommendations.\"\"\"\n","    user_idx = df_users[df_users['user_id'] == user_id].index[0]\n","    cb_similarities = cosine_similarity(content_matrix[user_idx], content_matrix).flatten()\n","    cb_ranks = {df_users.iloc[i]['user_id']: cb_similarities[i] for i in range(len(df_users)) if i != user_idx}\n","\n","    known_items = set(trainset.ur[trainset.to_inner_uid(user_id)])\n","    all_items = set(range(trainset.n_items))\n","    unknown_items = all_items - known_items\n","    cf_predictions = {iid: cf_model.predict(user_id, iid).est for iid in unknown_items}\n","\n","    hybrid_scores = {}\n","    for profile_id in set(cb_ranks.keys()).union(cf_predictions.keys()):\n","        cb_score = cb_ranks.get(profile_id, 0)\n","        cf_score = cf_predictions.get(profile_id, 0)\n","        hybrid_scores[profile_id] = 0.5 * cb_score + 0.5 * cf_score\n","\n","    top_profiles = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n","    return [profile_id for profile_id, _ in top_profiles]\n","\n","df_users = generate_users(100)\n","df_interactions = generate_interactions()\n","content_matrix, _ = build_content_matrix(df_users)\n","cf_model, trainset = build_cf_model(df_interactions)\n","\n","user_id = random.choice(df_users['user_id'].tolist())\n","print(f\"Hybrid Recommendations for User {user_id}: {hybrid_recommend(user_id, df_users, df_interactions, content_matrix, cf_model, trainset)}\")\n","\n","# Example of feedback integration\n","feedback_user_id = random.choice(df_users['user_id'].tolist())\n","feedback_profile_id = random.choice(df_users['user_id'].tolist())\n","feedback_rating = random.randint(1, 5)\n","df_interactions, cf_model, trainset = update_feedback(feedback_user_id, feedback_profile_id, feedback_rating, df_interactions, cf_model)\n"],"metadata":{"id":"oPR0R-ItA_Im","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743578689795,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"ef185285-e613-40f9-f4ff-3f41bba17b27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hybrid Recommendations for User 87: [53, 38, 84, 82, 58]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import random\n","import numpy as np\n","from datetime import datetime, timedelta\n","\n","def generate_interactions(n_users=100, n_items=50):\n","    interactions = []\n","    now = datetime.now()\n","\n","    for user in range(1, n_users + 1):\n","        for _ in range(random.randint(5, 15)):  # Each user interacts with 5-15 profiles\n","            profile = random.randint(1, n_items)\n","            rating = random.choice([1, 2, 3, 4, 5])\n","            timestamp = now - timedelta(days=random.randint(0, 90))  # Last 90 days\n","\n","            skipped = 1 if rating <= 2 else 0  # Assume lower ratings indicate skips\n","            messages = random.randint(0, 10) if rating >= 4 else 0  # More messages for high ratings\n","\n","            interactions.append((user, profile, rating, timestamp, skipped, messages))\n","\n","    return pd.DataFrame(interactions, columns=['user_id', 'profile_id', 'rating', 'timestamp', 'skipped', 'messages'])\n","\n","# Example usage\n","df_interactions = generate_interactions()\n","print(df_interactions.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7piHwd1KxmkT","executionInfo":{"status":"ok","timestamp":1743585177349,"user_tz":-330,"elapsed":26,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"2695a84a-38b0-4b5f-9b01-fdfac70519d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   user_id  profile_id  rating                  timestamp  skipped  messages\n","0        1          13       2 2025-02-26 09:15:11.139001        1         0\n","1        1          23       1 2025-02-04 09:15:11.139001        1         0\n","2        1          47       3 2025-02-28 09:15:11.139001        0         0\n","3        1          48       1 2025-03-08 09:15:11.139001        1         0\n","4        1          38       4 2025-02-21 09:15:11.139001        0         6\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import numpy as np\n","from collections import deque\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# DQN Model\n","def create_embeddings(df_users):\n","    df_users['content'] = df_users['interests'] + ' ' + df_users['personality'] + ' ' + df_users['MBTI']\n","    vectorizer = TfidfVectorizer()\n","    content_matrix = vectorizer.fit_transform(df_users['content']).toarray()\n","    return content_matrix\n","\n","class DQN(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        return self.fc3(x)\n","\n","class MatchDQNAgent:\n","    def __init__(self, state_dim, action_dim):\n","        self.state_dim = state_dim\n","        self.action_dim = action_dim\n","        self.model = DQN(state_dim, action_dim)\n","        self.target_model = DQN(state_dim, action_dim)\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n","        self.criterion = nn.MSELoss()\n","        self.memory = deque(maxlen=5000)\n","        self.epsilon = 1.0  # Exploration factor\n","        self.epsilon_min = 0.01\n","        self.epsilon_decay = 0.995  # Decay rate for epsilon\n","        self.gamma = 0.9    # Discount factor\n","\n","    def select_action(self, state):\n","        if random.random() < self.epsilon:\n","            return random.randint(0, self.action_dim - 1)\n","        else:\n","            with torch.no_grad():\n","                return torch.argmax(self.model(torch.FloatTensor(state))).item()\n","\n","    def train(self, batch_size=32):\n","        if len(self.memory) < batch_size:\n","            return\n","\n","        batch = random.sample(self.memory, batch_size)\n","        states, actions, rewards, next_states = zip(*batch)\n","\n","        states = torch.FloatTensor(states)\n","        actions = torch.LongTensor(actions)\n","        rewards = torch.FloatTensor(rewards)\n","        next_states = torch.FloatTensor(next_states)\n","\n","        q_values = self.model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n","        next_q_values = self.target_model(next_states).max(1)[0].detach()\n","        target_q_values = rewards + self.gamma * next_q_values\n","\n","        loss = self.criterion(q_values, target_q_values)\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        # Decay epsilon\n","        if self.epsilon > self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","\n","    def remember(self, state, action, reward, next_state):\n","        self.memory.append((state, action, reward, next_state))\n","\n","# Reward function update\n","import numpy as np\n","\n","import numpy as np\n","\n","def get_reward(df_interactions, user_id, profile_id, decay_factor=0.99):\n","    interactions = df_interactions[(df_interactions['user_id'] == user_id) &\n","                                   (df_interactions['profile_id'] == profile_id)].copy()  # Explicit copy to avoid warning\n","\n","    if interactions.empty:\n","        return 0  # No prior interaction, neutral reward\n","\n","    # Time decay: newer interactions contribute more\n","    max_timestamp = df_interactions['timestamp'].max()\n","    interactions['time_weight'] = np.exp(-decay_factor * (max_timestamp - interactions['timestamp']).dt.days)\n","\n","    # Base reward: Sum of ratings (assuming a 1-5 scale)\n","    reward = (interactions['rating'] * interactions['time_weight']).sum()\n","\n","    # Bonus for strong interest (ratings >= 4)\n","    reward += (2 * (interactions['rating'] >= 4) * interactions['time_weight']).sum()\n","\n","    # Penalize skips\n","    reward -= (3 * (interactions['skipped'] == 1) * interactions['time_weight']).sum()\n","\n","    # Reward for conversations\n","    reward += (5 * interactions['messages'] * interactions['time_weight']).sum()\n","\n","    return reward\n","\n","\n","\n","# State representation improvement\n","def build_state(user_embedding, user_id, df_interactions):\n","    past_matches = df_interactions[df_interactions['user_id'] == user_id]['profile_id'].values\n","    match_count = len(past_matches)\n","    engagement_score = df_interactions[df_interactions['user_id'] == user_id]['rating'].mean() if match_count > 0 else 0\n","\n","    return np.append(user_embedding, [match_count, engagement_score])\n","\n","\n","# Training the RL agent\n","def run_dqn_training(df_users, df_interactions, num_episodes=1000):\n","    embeddings = create_embeddings(df_users)\n","    state_dim = embeddings.shape[1] + 2  # Adding past match count & engagement score\n","    agent = MatchDQNAgent(state_dim=state_dim, action_dim=len(df_users))\n","\n","    for _ in range(num_episodes):\n","        user_idx = random.choice(range(len(df_users)))\n","        user_embedding = embeddings[user_idx]\n","        user_state = build_state(user_embedding, user_idx+1, df_interactions)\n","\n","        profile_idx = agent.select_action(user_state)\n","        profile_embedding = embeddings[profile_idx]\n","\n","        reward = get_reward(df_interactions, user_idx+1, profile_idx+1)\n","        next_state = build_state(user_embedding, user_idx+1, df_interactions)  # Assuming user state updates gradually\n","\n","        agent.remember(user_state, profile_idx, reward, next_state)\n","        agent.train()\n","\n","    return agent\n","\n","# Generate user data (for testing)\n","df_users = generate_users(100)\n","df_interactions = generate_interactions()\n","\n","# Initialize hybrid model and content-based recommendations\n","content_matrix = create_embeddings(df_users)\n","\n","# Train RL agent using interactions\n","agent = run_dqn_training(df_users, df_interactions, num_episodes=1000)\n","\n","# Example of generating recommendations for a user\n","user_id = random.choice(df_users['user_id'].tolist())\n","\n","# RL Agent recommendation\n","user_embedding = content_matrix[user_id-1]  # Example user embedding\n","user_state = build_state(user_embedding, user_id, df_interactions)\n","profile_idx = agent.select_action(user_state)\n","print(f\"RL Agent Recommendation for User {user_id}: {df_users.iloc[profile_idx]['name']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew_kDSE6W7fU","executionInfo":{"status":"ok","timestamp":1743585259544,"user_tz":-330,"elapsed":5872,"user":{"displayName":"Dinitha Wijewardhana","userId":"13542133001492852425"}},"outputId":"9ee35a48-7704-422a-8e90-fcda095460fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RL Agent Recommendation for User 88: Shawn Mejia\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mjbSzQbPrCgC"},"execution_count":null,"outputs":[]}]}